{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89866e02",
   "metadata": {},
   "source": [
    "## Title - A_guide_to_connecting_with_MongoDB_using_pymongo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13adb8d7",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c372595",
   "metadata": {},
   "source": [
    "This tutorial is deigned for users who want to connect to a MongoDb collection using the Pymongo library and generate statistics out of the data present in the collection. It assumes a basic knowledge of Python and MongoDB. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032235c1",
   "metadata": {},
   "source": [
    "**Learning Goal**\n",
    "By the end of this tutorial, an user will be able to connect to a MongoDB collection hosted on a server and display some statistics about the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a6766a",
   "metadata": {},
   "source": [
    "**Learning Objectives**\n",
    "- Install the pymongo Library\n",
    "- Explore the library to connect to a MongoDB collection\n",
    "- Generate some statistics out of the data\n",
    "- Obtain a data dump"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80645e57",
   "metadata": {},
   "source": [
    "**Description**\n",
    "\n",
    "MongoDB is a popular open-source, NoSQL database management system designed for high performance, scalability, and flexibility. \n",
    "It stores data in flexible, JSON-like documents, making it easy to work with structured and unstructured data. \n",
    "MongoDB uses a document-oriented data model, which allows for the storage of complex data structures and nested arrays,\n",
    "providing more flexibility than traditional relational databases. It supports features such as indexing, replication, sharding,\n",
    "and aggregation, making it suitable for a wide range of use cases, from small-scale applications to large-scale enterprise systems.\n",
    "PyMongo is the official Python client library for MongoDB. It allows Python developers to interact with MongoDB databases using a\n",
    "simple and intuitive API. With PyMongo, you can perform various operations such as querying, inserting, updating, and deleting\n",
    "documents in MongoDB collections directly from your Python code. It provides a flexible and powerful way to work with MongoDB \n",
    "databases, making it a popular choice for Python developers working with MongoDB. In this tutorial we will connect to an already \n",
    "existing MongoDB collection with the PyMongo library and generate some statistics out of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4f3d23",
   "metadata": {},
   "source": [
    "**Target Audience**\n",
    "\n",
    "This tutorial is meant for users who wants to use PyMongo library to connect to a MongoDB collection.\n",
    "This tutorial aims to put all related information in a single place\n",
    "\n",
    "**Prerequisites**\n",
    "\n",
    "    Basic knowledge of python (https://www.python.org/)\n",
    "    Basic knowledge of MongoDB (https://www.mongodb.com/)\n",    
    "    A local instance of MongoDB docker running in your system\n",
    "    Already stored data in MongoDB collection\n",


    "   \n",
    "**Difficulty Level**\n",
    "\n",
    "    Easy\n",
    "\n",
    "**Duration**\n",
    "\n",
    "    2 hours\n",
    "\n",
    "**Social Science Use Case**\n",
    "\n",
    "John is a researcher who wants to generate some statistics for a huge data that is collected and stored in MongoDB collection. For connecting and exploring the huge dataset, he uses the pymongo library to generate details about the collection like size of the collection, number of records, number of documents and generates a dump out of the collection. He can then re use this method for any other data collected and stored in MongoDB to generate statistics out of the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d707a7",
   "metadata": {},
   "source": [
    "**Sample Data**\n",
    "\n",
    "As a sample data we consider data from Telegram channels stored in MongoDB. The name of the database is telegram and the name of \n",
    "the collection is channel. The username is root and password is example \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4398a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to MongoDB database\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# MongoDB connection details\n",
    "mongo_host = 'localhost'\n",
    "mongo_port = 27017\n",
    "mongo_database = 'telegram'\n",
    "mongo_collection = 'channel'\n",
    "mongo_username = 'root'\n",
    "mongo_password = 'example'\n",
    "\n",
    "# Connection URI for MongoDB with authentication\n",
    "#mongo_uri = f\"mongodb://{mongo_username}:{mongo_password}@{mongo_host}:{mongo_port}/{mongo_database}\"\n",
    "\n",
    "mongo_uri=f\"mongodb://root:example@localhost:27017\"\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient(mongo_uri)\n",
    "\n",
    "# Specify the database and collection\n",
    "db = client[mongo_database]\n",
    "collection = db[mongo_collection]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a864a54d-11dc-4e46-bb2d-31b7014f8321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents in the 'channel' collection: 82602523\n"
     ]
    }
   ],
   "source": [
    "# Count the number of documents in the collection\n",
    "document_count = collection.count_documents({})\n",
    "\n",
    "# Print the result\n",
    "print(f\"Number of documents in the '{mongo_collection}' collection: {document_count}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84a924a1-717e-486d-8cc2-602acccbfaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ns': 'telegram.channel', 'size': 345146883805.0, 'count': 82603773, 'avgObjSize': 4178, 'storageSize': 118590033920.0, 'freeStorageSize': 270336, 'capped': False, 'wiredTiger': {'metadata': {'formatVersion': 1}, 'creationString': 'access_pattern_hint=none,allocation_size=4KB,app_metadata=(formatVersion=1),assert=(commit_timestamp=none,durable_timestamp=none,read_timestamp=none,write_timestamp=off),block_allocation=best,block_compressor=snappy,cache_resident=false,checksum=on,colgroups=,collator=,columns=,dictionary=0,encryption=(keyid=,name=),exclusive=false,extractor=,format=btree,huffman_key=,huffman_value=,ignore_in_memory_cache_size=false,immutable=false,import=(enabled=false,file_metadata=,repair=false),internal_item_max=0,internal_key_max=0,internal_key_truncate=true,internal_page_max=4KB,key_format=q,key_gap=10,leaf_item_max=0,leaf_key_max=0,leaf_page_max=32KB,leaf_value_max=64MB,log=(enabled=true),lsm=(auto_throttle=true,bloom=true,bloom_bit_count=16,bloom_config=,bloom_hash_count=8,bloom_oldest=false,chunk_count_limit=0,chunk_max=5GB,chunk_size=10MB,merge_custom=(prefix=,start_generation=0,suffix=),merge_max=15,merge_min=0),memory_page_image_max=0,memory_page_max=10m,os_cache_dirty_max=0,os_cache_max=0,prefix_compression=false,prefix_compression_min=4,readonly=false,source=,split_deepen_min_child=0,split_deepen_per_child=0,split_pct=90,tiered_object=false,tiered_storage=(auth_token=,bucket=,bucket_prefix=,cache_directory=,local_retention=300,name=,object_target_size=0),type=file,value_format=u,verbose=[],write_timestamp_usage=none', 'type': 'file', 'uri': 'statistics:table:collection-24-9208174452351198243', 'LSM': {'bloom filter false positives': 0, 'bloom filter hits': 0, 'bloom filter misses': 0, 'bloom filter pages evicted from cache': 0, 'bloom filter pages read into cache': 0, 'bloom filters in the LSM tree': 0, 'chunks in the LSM tree': 0, 'highest merge generation in the LSM tree': 0, 'queries that could have benefited from a Bloom filter that did not exist': 0, 'sleep for LSM checkpoint throttle': 0, 'sleep for LSM merge throttle': 0, 'total size of bloom filters': 0}, 'block-manager': {'allocations requiring file extension': 2721, 'blocks allocated': 4700, 'blocks freed': 2040, 'checkpoint size': 118589747200.0, 'file allocation unit size': 4096, 'file bytes available for reuse': 270336, 'file magic number': 120897, 'file major version number': 1, 'file size in bytes': 118590033920.0, 'minor version number': 0}, 'btree': {'btree checkpoint generation': 60, 'btree clean tree checkpoint expiration time': 0, 'btree compact pages reviewed': 0, 'btree compact pages selected to be rewritten': 0, 'btree compact pages skipped': 0, 'btree skipped by compaction as process would not reduce size': 0, 'column-store fixed-size leaf pages': 0, 'column-store internal pages': 0, 'column-store variable-size RLE encoded values': 0, 'column-store variable-size deleted values': 0, 'column-store variable-size leaf pages': 0, 'fixed-record size': 0, 'maximum internal page key size': 368, 'maximum internal page size': 4096, 'maximum leaf page key size': 2867, 'maximum leaf page size': 32768, 'maximum leaf page value size': 67108864, 'maximum tree depth': 6, 'number of key/value pairs': 0, 'overflow pages': 0, 'pages rewritten by compaction': 0, 'row-store empty values': 0, 'row-store internal pages': 0, 'row-store leaf pages': 0}, 'cache': {'bytes currently in the cache': 2868028819.0, 'bytes dirty in the cache cumulative': 112478843, 'bytes read into cache': 694449250542.0, 'bytes written from cache': 297683434, 'checkpoint blocked page eviction': 0, 'checkpoint of history store file blocked non-history store page eviction': 0, 'data source pages selected for eviction unable to be evicted': 12063, 'eviction gave up due to detecting an out of order on disk value behind the last update on the chain': 0, 'eviction gave up due to detecting an out of order tombstone ahead of the selected on disk update': 0, 'eviction gave up due to detecting an out of order tombstone ahead of the selected on disk update after validating the update chain': 0, 'eviction gave up due to detecting out of order timestamps on the update chain after the selected on disk update': 0, 'eviction walk passes of a file': 163598, 'eviction walk target pages histogram - 0-9': 4671, 'eviction walk target pages histogram - 10-31': 6817, 'eviction walk target pages histogram - 128 and higher': 0, 'eviction walk target pages histogram - 32-63': 11852, 'eviction walk target pages histogram - 64-128': 140258, 'eviction walk target pages reduced due to history store cache pressure': 0, 'eviction walks abandoned': 2843, 'eviction walks gave up because they restarted their walk twice': 0, 'eviction walks gave up because they saw too many pages and found no candidates': 918, 'eviction walks gave up because they saw too many pages and found too few candidates': 251, 'eviction walks reached end of tree': 3419, 'eviction walks restarted': 0, 'eviction walks started from root of tree': 4012, 'eviction walks started from saved location in tree': 159586, 'hazard pointer blocked page eviction': 6479, 'history store table insert calls': 0, 'history store table insert calls that returned restart': 0, 'history store table out-of-order resolved updates that lose their durable timestamp': 0, 'history store table out-of-order updates that were fixed up by reinserting with the fixed timestamp': 0, 'history store table reads': 0, 'history store table reads missed': 0, 'history store table reads requiring squashed modifies': 0, 'history store table truncation by rollback to stable to remove an unstable update': 0, 'history store table truncation by rollback to stable to remove an update': 0, 'history store table truncation to remove an update': 0, 'history store table truncation to remove range of updates due to key being removed from the data page during reconciliation': 0, 'history store table truncation to remove range of updates due to out-of-order timestamp update on data page': 0, 'history store table writes requiring squashed modifies': 0, 'in-memory page passed criteria to be split': 36, 'in-memory page splits': 18, 'internal pages evicted': 75707, 'internal pages split during eviction': 0, 'leaf pages split during eviction': 35, 'modified pages evicted': 54, 'overflow pages read into cache': 0, 'page split during eviction deepened the tree': 0, 'page written requiring history store records': 0, 'pages read into cache': 12233996, 'pages read into cache after truncate': 0, 'pages read into cache after truncate in prepare state': 0, 'pages requested from the cache': 16571109, 'pages seen by eviction walk': 16389134, 'pages written from cache': 4610, 'pages written requiring in-memory restoration': 3, 'the number of times full update inserted to history store': 0, 'the number of times reverse modify inserted to history store': 0, 'tracked dirty bytes in the cache': 9501031, 'unmodified pages evicted': 12158317}, 'cache_walk': {'Average difference between current eviction generation when the page was last considered': 0, 'Average on-disk page image size seen': 0, 'Average time in cache for pages that have been visited by the eviction server': 0, 'Average time in cache for pages that have not been visited by the eviction server': 0, 'Clean pages currently in cache': 0, 'Current eviction generation': 0, 'Dirty pages currently in cache': 0, 'Entries in the root page': 0, 'Internal pages currently in cache': 0, 'Leaf pages currently in cache': 0, 'Maximum difference between current eviction generation when the page was last considered': 0, 'Maximum page size seen': 0, 'Minimum on-disk page image size seen': 0, 'Number of pages never visited by eviction server': 0, 'On-disk page image sizes smaller than a single allocation unit': 0, 'Pages created in memory and never written': 0, 'Pages currently queued for eviction': 0, 'Pages that could not be queued for eviction': 0, 'Refs skipped during cache traversal': 0, 'Size of the root page': 0, 'Total number of pages currently in cache': 0}, 'checkpoint-cleanup': {'pages added for eviction': 0, 'pages removed': 0, 'pages skipped during tree walk': 168974639, 'pages visited': 172247789}, 'compression': {'compressed page maximum internal page size prior to compression': 4096, 'compressed page maximum leaf page size prior to compression ': 131072, 'compressed pages read': 12119915, 'compressed pages written': 4017, 'page written failed to compress': 0, 'page written was too small to compress': 593}, 'cursor': {'Total number of entries skipped by cursor next calls': 0, 'Total number of entries skipped by cursor prev calls': 0, 'Total number of entries skipped to position the history store cursor': 0, 'Total number of times a search near has exited due to prefix config': 0, 'bulk loaded cursor insert calls': 0, 'cache cursors reuse count': 960, 'close calls that result in cache': 963, 'create calls': 4, 'cursor next calls that skip due to a globally visible history store tombstone': 0, 'cursor next calls that skip greater than or equal to 100 entries': 0, 'cursor next calls that skip less than 100 entries': 165165278, 'cursor prev calls that skip due to a globally visible history store tombstone': 0, 'cursor prev calls that skip greater than or equal to 100 entries': 0, 'cursor prev calls that skip less than 100 entries': 1, 'insert calls': 62136, 'insert key and value bytes': 206617061, 'modify': 0, 'modify key and value bytes affected': 0, 'modify value bytes modified': 0, 'next calls': 165165278, 'open cursor count': 0, 'operation restarted': 0, 'prev calls': 1, 'remove calls': 0, 'remove key bytes removed': 0, 'reserve calls': 0, 'reset calls': 179592, 'search calls': 0, 'search history store calls': 0, 'search near calls': 177617, 'truncate calls': 0, 'update calls': 0, 'update key and value bytes': 0, 'update value size change': 0}, 'reconciliation': {'approximate byte size of timestamps in pages written': 0, 'approximate byte size of transaction IDs in pages written': 0, 'dictionary matches': 0, 'fast-path pages deleted': 0, 'internal page key bytes discarded using suffix compression': 7990, 'internal page multi-block writes': 44, 'internal-page overflow keys': 0, 'leaf page key bytes discarded using prefix compression': 0, 'leaf page multi-block writes': 61, 'leaf-page overflow keys': 0, 'maximum blocks required for a page': 4, 'overflow values written': 0, 'page checksum matches': 0, 'page reconciliation calls': 243, 'page reconciliation calls for eviction': 5, 'pages deleted': 0, 'pages written including an aggregated newest start durable timestamp ': 0, 'pages written including an aggregated newest stop durable timestamp ': 0, 'pages written including an aggregated newest stop timestamp ': 0, 'pages written including an aggregated newest stop transaction ID': 0, 'pages written including an aggregated newest transaction ID ': 0, 'pages written including an aggregated oldest start timestamp ': 0, 'pages written including an aggregated prepare': 0, 'pages written including at least one prepare': 0, 'pages written including at least one start durable timestamp': 0, 'pages written including at least one start timestamp': 0, 'pages written including at least one start transaction ID': 0, 'pages written including at least one stop durable timestamp': 0, 'pages written including at least one stop timestamp': 0, 'pages written including at least one stop transaction ID': 0, 'records written including a prepare': 0, 'records written including a start durable timestamp': 0, 'records written including a start timestamp': 0, 'records written including a start transaction ID': 0, 'records written including a stop durable timestamp': 0, 'records written including a stop timestamp': 0, 'records written including a stop transaction ID': 0}, 'session': {'object compaction': 0, 'tiered operations dequeued and processed': 0, 'tiered operations scheduled': 0, 'tiered storage local retention time (secs)': 0}, 'transaction': {'checkpoint has acquired a snapshot for its transaction': 0, 'race to read prepared update retry': 0, 'rollback to stable history store records with stop timestamps older than newer records': 0, 'rollback to stable inconsistent checkpoint': 0, 'rollback to stable keys removed': 0, 'rollback to stable keys restored': 0, 'rollback to stable restored tombstones from history store': 0, 'rollback to stable restored updates from history store': 0, 'rollback to stable skipping delete rle': 0, 'rollback to stable skipping stable rle': 0, 'rollback to stable sweeping history store keys': 0, 'rollback to stable updates removed from history store': 0, 'transaction checkpoints due to obsolete pages': 0, 'update conflicts': 0}}, 'nindexes': 2, 'indexDetails': {'_id_': {'metadata': {'formatVersion': 8}, 'creationString': 'access_pattern_hint=none,allocation_size=4KB,app_metadata=(formatVersion=8),assert=(commit_timestamp=none,durable_timestamp=none,read_timestamp=none,write_timestamp=off),block_allocation=best,block_compressor=,cache_resident=false,checksum=on,colgroups=,collator=,columns=,dictionary=0,encryption=(keyid=,name=),exclusive=false,extractor=,format=btree,huffman_key=,huffman_value=,ignore_in_memory_cache_size=false,immutable=false,import=(enabled=false,file_metadata=,repair=false),internal_item_max=0,internal_key_max=0,internal_key_truncate=true,internal_page_max=16k,key_format=u,key_gap=10,leaf_item_max=0,leaf_key_max=0,leaf_page_max=16k,leaf_value_max=0,log=(enabled=true),lsm=(auto_throttle=true,bloom=true,bloom_bit_count=16,bloom_config=,bloom_hash_count=8,bloom_oldest=false,chunk_count_limit=0,chunk_max=5GB,chunk_size=10MB,merge_custom=(prefix=,start_generation=0,suffix=),merge_max=15,merge_min=0),memory_page_image_max=0,memory_page_max=5MB,os_cache_dirty_max=0,os_cache_max=0,prefix_compression=true,prefix_compression_min=4,readonly=false,source=,split_deepen_min_child=0,split_deepen_per_child=0,split_pct=90,tiered_object=false,tiered_storage=(auth_token=,bucket=,bucket_prefix=,cache_directory=,local_retention=300,name=,object_target_size=0),type=file,value_format=u,verbose=[],write_timestamp_usage=none', 'type': 'file', 'uri': 'statistics:table:index-25-9208174452351198243', 'LSM': {'bloom filter false positives': 0, 'bloom filter hits': 0, 'bloom filter misses': 0, 'bloom filter pages evicted from cache': 0, 'bloom filter pages read into cache': 0, 'bloom filters in the LSM tree': 0, 'chunks in the LSM tree': 0, 'highest merge generation in the LSM tree': 0, 'queries that could have benefited from a Bloom filter that did not exist': 0, 'sleep for LSM checkpoint throttle': 0, 'sleep for LSM merge throttle': 0, 'total size of bloom filters': 0}, 'block-manager': {'allocations requiring file extension': 47, 'blocks allocated': 804, 'blocks freed': 602, 'checkpoint size': 1365098496.0, 'file allocation unit size': 4096, 'file bytes available for reuse': 1654784, 'file magic number': 120897, 'file major version number': 1, 'file size in bytes': 1366773760.0, 'minor version number': 0}, 'btree': {'btree checkpoint generation': 60, 'btree clean tree checkpoint expiration time': 0, 'btree compact pages reviewed': 0, 'btree compact pages selected to be rewritten': 0, 'btree compact pages skipped': 0, 'btree skipped by compaction as process would not reduce size': 0, 'column-store fixed-size leaf pages': 0, 'column-store internal pages': 0, 'column-store variable-size RLE encoded values': 0, 'column-store variable-size deleted values': 0, 'column-store variable-size leaf pages': 0, 'fixed-record size': 0, 'maximum internal page key size': 1474, 'maximum internal page size': 16384, 'maximum leaf page key size': 1474, 'maximum leaf page size': 16384, 'maximum leaf page value size': 7372, 'maximum tree depth': 5, 'number of key/value pairs': 0, 'overflow pages': 0, 'pages rewritten by compaction': 0, 'row-store empty values': 0, 'row-store internal pages': 0, 'row-store leaf pages': 0}, 'cache': {'bytes currently in the cache': 525022, 'bytes dirty in the cache cumulative': 54343104, 'bytes read into cache': 168101, 'bytes written from cache': 9515151, 'checkpoint blocked page eviction': 0, 'checkpoint of history store file blocked non-history store page eviction': 0, 'data source pages selected for eviction unable to be evicted': 0, 'eviction gave up due to detecting an out of order on disk value behind the last update on the chain': 0, 'eviction gave up due to detecting an out of order tombstone ahead of the selected on disk update': 0, 'eviction gave up due to detecting an out of order tombstone ahead of the selected on disk update after validating the update chain': 0, 'eviction gave up due to detecting out of order timestamps on the update chain after the selected on disk update': 0, 'eviction walk passes of a file': 1766, 'eviction walk target pages histogram - 0-9': 1728, 'eviction walk target pages histogram - 10-31': 38, 'eviction walk target pages histogram - 128 and higher': 0, 'eviction walk target pages histogram - 32-63': 0, 'eviction walk target pages histogram - 64-128': 0, 'eviction walk target pages reduced due to history store cache pressure': 0, 'eviction walks abandoned': 0, 'eviction walks gave up because they restarted their walk twice': 1765, 'eviction walks gave up because they saw too many pages and found no candidates': 0, 'eviction walks gave up because they saw too many pages and found too few candidates': 0, 'eviction walks reached end of tree': 3531, 'eviction walks restarted': 0, 'eviction walks started from root of tree': 1765, 'eviction walks started from saved location in tree': 1, 'hazard pointer blocked page eviction': 0, 'history store table insert calls': 0, 'history store table insert calls that returned restart': 0, 'history store table out-of-order resolved updates that lose their durable timestamp': 0, 'history store table out-of-order updates that were fixed up by reinserting with the fixed timestamp': 0, 'history store table reads': 0, 'history store table reads missed': 0, 'history store table reads requiring squashed modifies': 0, 'history store table truncation by rollback to stable to remove an unstable update': 0, 'history store table truncation by rollback to stable to remove an update': 0, 'history store table truncation to remove an update': 0, 'history store table truncation to remove range of updates due to key being removed from the data page during reconciliation': 0, 'history store table truncation to remove range of updates due to out-of-order timestamp update on data page': 0, 'history store table writes requiring squashed modifies': 0, 'in-memory page passed criteria to be split': 0, 'in-memory page splits': 0, 'internal pages evicted': 0, 'internal pages split during eviction': 0, 'leaf pages split during eviction': 11, 'modified pages evicted': 11, 'overflow pages read into cache': 0, 'page split during eviction deepened the tree': 0, 'page written requiring history store records': 0, 'pages read into cache': 15, 'pages read into cache after truncate': 0, 'pages read into cache after truncate in prepare state': 0, 'pages requested from the cache': 186633, 'pages seen by eviction walk': 7048, 'pages written from cache': 714, 'pages written requiring in-memory restoration': 0, 'the number of times full update inserted to history store': 0, 'the number of times reverse modify inserted to history store': 0, 'tracked dirty bytes in the cache': 434796, 'unmodified pages evicted': 0}, 'cache_walk': {'Average difference between current eviction generation when the page was last considered': 0, 'Average on-disk page image size seen': 0, 'Average time in cache for pages that have been visited by the eviction server': 0, 'Average time in cache for pages that have not been visited by the eviction server': 0, 'Clean pages currently in cache': 0, 'Current eviction generation': 0, 'Dirty pages currently in cache': 0, 'Entries in the root page': 0, 'Internal pages currently in cache': 0, 'Leaf pages currently in cache': 0, 'Maximum difference between current eviction generation when the page was last considered': 0, 'Maximum page size seen': 0, 'Minimum on-disk page image size seen': 0, 'Number of pages never visited by eviction server': 0, 'On-disk page image sizes smaller than a single allocation unit': 0, 'Pages created in memory and never written': 0, 'Pages currently queued for eviction': 0, 'Pages that could not be queued for eviction': 0, 'Refs skipped during cache traversal': 0, 'Size of the root page': 0, 'Total number of pages currently in cache': 0}, 'checkpoint-cleanup': {'pages added for eviction': 0, 'pages removed': 0, 'pages skipped during tree walk': 43036, 'pages visited': 43171}, 'compression': {'compressed page maximum internal page size prior to compression': 16384, 'compressed page maximum leaf page size prior to compression ': 16384, 'compressed pages read': 0, 'compressed pages written': 0, 'page written failed to compress': 0, 'page written was too small to compress': 0}, 'cursor': {'Total number of entries skipped by cursor next calls': 0, 'Total number of entries skipped by cursor prev calls': 0, 'Total number of entries skipped to position the history store cursor': 0, 'Total number of times a search near has exited due to prefix config': 0, 'bulk loaded cursor insert calls': 0, 'cache cursors reuse count': 501, 'close calls that result in cache': 503, 'create calls': 3, 'cursor next calls that skip due to a globally visible history store tombstone': 0, 'cursor next calls that skip greater than or equal to 100 entries': 0, 'cursor next calls that skip less than 100 entries': 0, 'cursor prev calls that skip due to a globally visible history store tombstone': 0, 'cursor prev calls that skip greater than or equal to 100 entries': 0, 'cursor prev calls that skip less than 100 entries': 0, 'insert calls': 62136, 'insert key and value bytes': 1180584, 'modify': 0, 'modify key and value bytes affected': 0, 'modify value bytes modified': 0, 'next calls': 0, 'open cursor count': 0, 'operation restarted': 0, 'prev calls': 0, 'remove calls': 0, 'remove key bytes removed': 0, 'reserve calls': 0, 'reset calls': 62639, 'search calls': 0, 'search history store calls': 0, 'search near calls': 0, 'truncate calls': 0, 'update calls': 0, 'update key and value bytes': 0, 'update value size change': 0}, 'reconciliation': {'approximate byte size of timestamps in pages written': 0, 'approximate byte size of transaction IDs in pages written': 0, 'dictionary matches': 0, 'fast-path pages deleted': 0, 'internal page key bytes discarded using suffix compression': 2212, 'internal page multi-block writes': 0, 'internal-page overflow keys': 0, 'leaf page key bytes discarded using prefix compression': 3443382, 'leaf page multi-block writes': 44, 'leaf-page overflow keys': 0, 'maximum blocks required for a page': 1, 'overflow values written': 0, 'page checksum matches': 0, 'page reconciliation calls': 180, 'page reconciliation calls for eviction': 0, 'pages deleted': 0, 'pages written including an aggregated newest start durable timestamp ': 0, 'pages written including an aggregated newest stop durable timestamp ': 0, 'pages written including an aggregated newest stop timestamp ': 0, 'pages written including an aggregated newest stop transaction ID': 0, 'pages written including an aggregated newest transaction ID ': 0, 'pages written including an aggregated oldest start timestamp ': 0, 'pages written including an aggregated prepare': 0, 'pages written including at least one prepare': 0, 'pages written including at least one start durable timestamp': 0, 'pages written including at least one start timestamp': 0, 'pages written including at least one start transaction ID': 0, 'pages written including at least one stop durable timestamp': 0, 'pages written including at least one stop timestamp': 0, 'pages written including at least one stop transaction ID': 0, 'records written including a prepare': 0, 'records written including a start durable timestamp': 0, 'records written including a start timestamp': 0, 'records written including a start transaction ID': 0, 'records written including a stop durable timestamp': 0, 'records written including a stop timestamp': 0, 'records written including a stop transaction ID': 0}, 'session': {'object compaction': 0, 'tiered operations dequeued and processed': 0, 'tiered operations scheduled': 0, 'tiered storage local retention time (secs)': 0}, 'transaction': {'checkpoint has acquired a snapshot for its transaction': 0, 'race to read prepared update retry': 0, 'rollback to stable history store records with stop timestamps older than newer records': 0, 'rollback to stable inconsistent checkpoint': 0, 'rollback to stable keys removed': 0, 'rollback to stable keys restored': 0, 'rollback to stable restored tombstones from history store': 0, 'rollback to stable restored updates from history store': 0, 'rollback to stable skipping delete rle': 0, 'rollback to stable skipping stable rle': 0, 'rollback to stable sweeping history store keys': 0, 'rollback to stable updates removed from history store': 0, 'transaction checkpoints due to obsolete pages': 0, 'update conflicts': 0}}, 'channel_id_1': {'metadata': {'formatVersion': 8}, 'creationString': 'access_pattern_hint=none,allocation_size=4KB,app_metadata=(formatVersion=8),assert=(commit_timestamp=none,durable_timestamp=none,read_timestamp=none,write_timestamp=off),block_allocation=best,block_compressor=,cache_resident=false,checksum=on,colgroups=,collator=,columns=,dictionary=0,encryption=(keyid=,name=),exclusive=false,extractor=,format=btree,huffman_key=,huffman_value=,ignore_in_memory_cache_size=false,immutable=false,import=(enabled=false,file_metadata=,repair=false),internal_item_max=0,internal_key_max=0,internal_key_truncate=true,internal_page_max=16k,key_format=u,key_gap=10,leaf_item_max=0,leaf_key_max=0,leaf_page_max=16k,leaf_value_max=0,log=(enabled=true),lsm=(auto_throttle=true,bloom=true,bloom_bit_count=16,bloom_config=,bloom_hash_count=8,bloom_oldest=false,chunk_count_limit=0,chunk_max=5GB,chunk_size=10MB,merge_custom=(prefix=,start_generation=0,suffix=),merge_max=15,merge_min=0),memory_page_image_max=0,memory_page_max=5MB,os_cache_dirty_max=0,os_cache_max=0,prefix_compression=true,prefix_compression_min=4,readonly=false,source=,split_deepen_min_child=0,split_deepen_per_child=0,split_pct=90,tiered_object=false,tiered_storage=(auth_token=,bucket=,bucket_prefix=,cache_directory=,local_retention=300,name=,object_target_size=0),type=file,value_format=u,verbose=[],write_timestamp_usage=none', 'type': 'file', 'uri': 'statistics:table:index-0-3047515787296799585', 'LSM': {'bloom filter false positives': 0, 'bloom filter hits': 0, 'bloom filter misses': 0, 'bloom filter pages evicted from cache': 0, 'bloom filter pages read into cache': 0, 'bloom filters in the LSM tree': 0, 'chunks in the LSM tree': 0, 'highest merge generation in the LSM tree': 0, 'queries that could have benefited from a Bloom filter that did not exist': 0, 'sleep for LSM checkpoint throttle': 0, 'sleep for LSM merge throttle': 0, 'total size of bloom filters': 0}, 'block-manager': {'allocations requiring file extension': 19, 'blocks allocated': 376, 'blocks freed': 186, 'checkpoint size': 383324160, 'file allocation unit size': 4096, 'file bytes available for reuse': 2646016, 'file magic number': 120897, 'file major version number': 1, 'file size in bytes': 385994752, 'minor version number': 0}, 'btree': {'btree checkpoint generation': 60, 'btree clean tree checkpoint expiration time': 0, 'btree compact pages reviewed': 0, 'btree compact pages selected to be rewritten': 0, 'btree compact pages skipped': 0, 'btree skipped by compaction as process would not reduce size': 0, 'column-store fixed-size leaf pages': 0, 'column-store internal pages': 0, 'column-store variable-size RLE encoded values': 0, 'column-store variable-size deleted values': 0, 'column-store variable-size leaf pages': 0, 'fixed-record size': 0, 'maximum internal page key size': 1474, 'maximum internal page size': 16384, 'maximum leaf page key size': 1474, 'maximum leaf page size': 16384, 'maximum leaf page value size': 7372, 'maximum tree depth': 4, 'number of key/value pairs': 0, 'overflow pages': 0, 'pages rewritten by compaction': 0, 'row-store empty values': 0, 'row-store internal pages': 0, 'row-store leaf pages': 0}, 'cache': {'bytes currently in the cache': 524716, 'bytes dirty in the cache cumulative': 17732057, 'bytes read into cache': 1170228, 'bytes written from cache': 2764336, 'checkpoint blocked page eviction': 0, 'checkpoint of history store file blocked non-history store page eviction': 0, 'data source pages selected for eviction unable to be evicted': 0, 'eviction gave up due to detecting an out of order on disk value behind the last update on the chain': 0, 'eviction gave up due to detecting an out of order tombstone ahead of the selected on disk update': 0, 'eviction gave up due to detecting an out of order tombstone ahead of the selected on disk update after validating the update chain': 0, 'eviction gave up due to detecting out of order timestamps on the update chain after the selected on disk update': 0, 'eviction walk passes of a file': 1505, 'eviction walk target pages histogram - 0-9': 1451, 'eviction walk target pages histogram - 10-31': 54, 'eviction walk target pages histogram - 128 and higher': 0, 'eviction walk target pages histogram - 32-63': 0, 'eviction walk target pages histogram - 64-128': 0, 'eviction walk target pages reduced due to history store cache pressure': 0, 'eviction walks abandoned': 0, 'eviction walks gave up because they restarted their walk twice': 1498, 'eviction walks gave up because they saw too many pages and found no candidates': 0, 'eviction walks gave up because they saw too many pages and found too few candidates': 0, 'eviction walks reached end of tree': 3002, 'eviction walks restarted': 0, 'eviction walks started from root of tree': 1498, 'eviction walks started from saved location in tree': 7, 'hazard pointer blocked page eviction': 0, 'history store table insert calls': 0, 'history store table insert calls that returned restart': 0, 'history store table out-of-order resolved updates that lose their durable timestamp': 0, 'history store table out-of-order updates that were fixed up by reinserting with the fixed timestamp': 0, 'history store table reads': 0, 'history store table reads missed': 0, 'history store table reads requiring squashed modifies': 0, 'history store table truncation by rollback to stable to remove an unstable update': 0, 'history store table truncation by rollback to stable to remove an update': 0, 'history store table truncation to remove an update': 0, 'history store table truncation to remove range of updates due to key being removed from the data page during reconciliation': 0, 'history store table truncation to remove range of updates due to out-of-order timestamp update on data page': 0, 'history store table writes requiring squashed modifies': 0, 'in-memory page passed criteria to be split': 0, 'in-memory page splits': 0, 'internal pages evicted': 0, 'internal pages split during eviction': 0, 'leaf pages split during eviction': 51, 'modified pages evicted': 81, 'overflow pages read into cache': 0, 'page split during eviction deepened the tree': 0, 'page written requiring history store records': 0, 'pages read into cache': 84, 'pages read into cache after truncate': 0, 'pages read into cache after truncate in prepare state': 0, 'pages requested from the cache': 124824, 'pages seen by eviction walk': 8962, 'pages written from cache': 286, 'pages written requiring in-memory restoration': 0, 'the number of times full update inserted to history store': 0, 'the number of times reverse modify inserted to history store': 0, 'tracked dirty bytes in the cache': 468823, 'unmodified pages evicted': 0}, 'cache_walk': {'Average difference between current eviction generation when the page was last considered': 0, 'Average on-disk page image size seen': 0, 'Average time in cache for pages that have been visited by the eviction server': 0, 'Average time in cache for pages that have not been visited by the eviction server': 0, 'Clean pages currently in cache': 0, 'Current eviction generation': 0, 'Dirty pages currently in cache': 0, 'Entries in the root page': 0, 'Internal pages currently in cache': 0, 'Leaf pages currently in cache': 0, 'Maximum difference between current eviction generation when the page was last considered': 0, 'Maximum page size seen': 0, 'Minimum on-disk page image size seen': 0, 'Number of pages never visited by eviction server': 0, 'On-disk page image sizes smaller than a single allocation unit': 0, 'Pages created in memory and never written': 0, 'Pages currently queued for eviction': 0, 'Pages that could not be queued for eviction': 0, 'Refs skipped during cache traversal': 0, 'Size of the root page': 0, 'Total number of pages currently in cache': 0}, 'checkpoint-cleanup': {'pages added for eviction': 0, 'pages removed': 0, 'pages skipped during tree walk': 27120, 'pages visited': 27627}, 'compression': {'compressed page maximum internal page size prior to compression': 16384, 'compressed page maximum leaf page size prior to compression ': 16384, 'compressed pages read': 0, 'compressed pages written': 0, 'page written failed to compress': 0, 'page written was too small to compress': 0}, 'cursor': {'Total number of entries skipped by cursor next calls': 0, 'Total number of entries skipped by cursor prev calls': 0, 'Total number of entries skipped to position the history store cursor': 0, 'Total number of times a search near has exited due to prefix config': 0, 'bulk loaded cursor insert calls': 0, 'cache cursors reuse count': 461, 'close calls that result in cache': 463, 'create calls': 3, 'cursor next calls that skip due to a globally visible history store tombstone': 0, 'cursor next calls that skip greater than or equal to 100 entries': 0, 'cursor next calls that skip less than 100 entries': 0, 'cursor prev calls that skip due to a globally visible history store tombstone': 0, 'cursor prev calls that skip greater than or equal to 100 entries': 0, 'cursor prev calls that skip less than 100 entries': 0, 'insert calls': 62136, 'insert key and value bytes': 683496, 'modify': 0, 'modify key and value bytes affected': 0, 'modify value bytes modified': 0, 'next calls': 0, 'open cursor count': 0, 'operation restarted': 0, 'prev calls': 0, 'remove calls': 0, 'remove key bytes removed': 0, 'reserve calls': 0, 'reset calls': 62599, 'search calls': 0, 'search history store calls': 0, 'search near calls': 0, 'truncate calls': 0, 'update calls': 0, 'update key and value bytes': 0, 'update value size change': 0}, 'reconciliation': {'approximate byte size of timestamps in pages written': 0, 'approximate byte size of transaction IDs in pages written': 0, 'dictionary matches': 0, 'fast-path pages deleted': 0, 'internal page key bytes discarded using suffix compression': 261, 'internal page multi-block writes': 0, 'internal-page overflow keys': 0, 'leaf page key bytes discarded using prefix compression': 3545525, 'leaf page multi-block writes': 75, 'leaf-page overflow keys': 0, 'maximum blocks required for a page': 1, 'overflow values written': 0, 'page checksum matches': 0, 'page reconciliation calls': 202, 'page reconciliation calls for eviction': 1, 'pages deleted': 0, 'pages written including an aggregated newest start durable timestamp ': 0, 'pages written including an aggregated newest stop durable timestamp ': 0, 'pages written including an aggregated newest stop timestamp ': 0, 'pages written including an aggregated newest stop transaction ID': 0, 'pages written including an aggregated newest transaction ID ': 0, 'pages written including an aggregated oldest start timestamp ': 0, 'pages written including an aggregated prepare': 0, 'pages written including at least one prepare': 0, 'pages written including at least one start durable timestamp': 0, 'pages written including at least one start timestamp': 0, 'pages written including at least one start transaction ID': 0, 'pages written including at least one stop durable timestamp': 0, 'pages written including at least one stop timestamp': 0, 'pages written including at least one stop transaction ID': 0, 'records written including a prepare': 0, 'records written including a start durable timestamp': 0, 'records written including a start timestamp': 0, 'records written including a start transaction ID': 0, 'records written including a stop durable timestamp': 0, 'records written including a stop timestamp': 0, 'records written including a stop transaction ID': 0}, 'session': {'object compaction': 0, 'tiered operations dequeued and processed': 0, 'tiered operations scheduled': 0, 'tiered storage local retention time (secs)': 0}, 'transaction': {'checkpoint has acquired a snapshot for its transaction': 0, 'race to read prepared update retry': 0, 'rollback to stable history store records with stop timestamps older than newer records': 0, 'rollback to stable inconsistent checkpoint': 0, 'rollback to stable keys removed': 0, 'rollback to stable keys restored': 0, 'rollback to stable restored tombstones from history store': 0, 'rollback to stable restored updates from history store': 0, 'rollback to stable skipping delete rle': 0, 'rollback to stable skipping stable rle': 0, 'rollback to stable sweeping history store keys': 0, 'rollback to stable updates removed from history store': 0, 'transaction checkpoints due to obsolete pages': 0, 'update conflicts': 0}}}, 'indexBuilds': [], 'totalIndexSize': 1752768512.0, 'totalSize': 120342802432.0, 'indexSizes': {'_id_': 1366773760.0, 'channel_id_1': 385994752}, 'scaleFactor': 1, 'ok': 1.0}\n"
     ]
    }
   ],
   "source": [
    "#print statistics out of the data\n",
    "stats = db.command(\"collstats\", mongo_collection)\n",
    "print(stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c0e5917-3099-4a44-8b4d-b5ed597e8211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('65ae71c72fff6da70b8f7e4a'), 'record_id': 8134311851216338949, 'message_id': 5, 'channel_id': 1893917064, 'retrieved_utc': 1705931207, 'updated_utc': 1705931207, 'data': '{\"_\": \"Message\", \"id\": 5, \"peer_id\": {\"_\": \"PeerChannel\", \"channel_id\": 1893917064}, \"date\": \"2023-10-15T08:21:44+00:00\", \"message\": \"https://t.me/+TVKXr6DVofhWZlqH\", \"out\": false, \"mentioned\": false, \"media_unread\": false, \"silent\": false, \"post\": true, \"from_scheduled\": false, \"legacy\": false, \"edit_hide\": false, \"pinned\": false, \"noforwards\": false, \"from_id\": null, \"fwd_from\": null, \"via_bot_id\": null, \"reply_to\": {\"_\": \"MessageReplyHeader\", \"reply_to_msg_id\": 4, \"reply_to_scheduled\": false, \"forum_topic\": false, \"reply_to_peer_id\": null, \"reply_to_top_id\": null}, \"media\": null, \"reply_markup\": null, \"entities\": [{\"_\": \"MessageEntityUrl\", \"offset\": 0, \"length\": 30}], \"views\": 10638, \"forwards\": 107, \"replies\": null, \"edit_date\": \"2023-10-15T16:25:07+00:00\", \"post_author\": null, \"grouped_id\": null, \"reactions\": {\"_\": \"MessageReactions\", \"results\": [{\"_\": \"ReactionCount\", \"reaction\": {\"_\": \"ReactionEmoji\", \"emoticon\": \"\\\\ud83d\\\\udc4d\"}, \"count\": 24, \"chosen_order\": null}, {\"_\": \"ReactionCount\", \"reaction\": {\"_\": \"ReactionEmoji\", \"emoticon\": \"\\\\ud83e\\\\udd74\"}, \"count\": 11, \"chosen_order\": null}, {\"_\": \"ReactionCount\", \"reaction\": {\"_\": \"ReactionEmoji\", \"emoticon\": \"\\\\u2764\"}, \"count\": 6, \"chosen_order\": null}, {\"_\": \"ReactionCount\", \"reaction\": {\"_\": \"ReactionEmoji\", \"emoticon\": \"\\\\ud83e\\\\udd70\"}, \"count\": 6, \"chosen_order\": null}], \"min\": false, \"can_see_list\": false, \"recent_reactions\": []}, \"restriction_reason\": [], \"ttl_period\": null}'}\n"
     ]
    }
   ],
   "source": [
    "#print one document out of the data\n",
    "one_document = collection.find_one()\n",
    "print(one_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65ba833b-d069-473a-af01-9f747de17d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25a3741d-9d74-4bee-8f30-6729e2a77681",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = [\n",
    "    {\"$group\": {\"_id\": \"$channel_id\", \"count\": {\"$sum\": 1}}}\n",
    "]\n",
    "# Execute the aggregation pipeline\n",
    "result = list(collection.aggregate(pipeline))\n",
    "\n",
    "# Print the results\n",
    "df = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3533cc42-3ac5-45c3-bd80-1331af516506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1296944294</td>\n",
       "      <td>7415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1158379858</td>\n",
       "      <td>916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1076967923</td>\n",
       "      <td>5824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1074418185</td>\n",
       "      <td>4433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1788633993</td>\n",
       "      <td>1630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6798</th>\n",
       "      <td>1122432103</td>\n",
       "      <td>13405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6799</th>\n",
       "      <td>1594967462</td>\n",
       "      <td>2666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6800</th>\n",
       "      <td>1232912002</td>\n",
       "      <td>7723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6801</th>\n",
       "      <td>1314318233</td>\n",
       "      <td>13373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6802</th>\n",
       "      <td>1099534817</td>\n",
       "      <td>830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6803 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             _id  count\n",
       "0     1296944294   7415\n",
       "1     1158379858    916\n",
       "2     1076967923   5824\n",
       "3     1074418185   4433\n",
       "4     1788633993   1630\n",
       "...          ...    ...\n",
       "6798  1122432103  13405\n",
       "6799  1594967462   2666\n",
       "6800  1232912002   7723\n",
       "6801  1314318233  13373\n",
       "6802  1099534817    830\n",
       "\n",
       "[6803 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of unique channels in the collection , groupby channel_id\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee718079-fe63-4100-84b2-3825fea4b366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['_id', 'count'], dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a0ad2de5-d7a9-4462-b47b-18b2275ad734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Channel with the minimum count\n",
    "min_count_channel = df.loc[df['count'].idxmin()]\n",
    "\n",
    "# Channel with the maximum count\n",
    "max_count_channel = df.loc[df['count'].idxmax()]\n",
    "\n",
    "# Average count across all channels\n",
    "average_count = df['count'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "04debe1a-94dc-4636-be73-8dd5c041703a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10001.887608069164"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe9724f9-5f4c-4e48-9169-4fd64460202a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_id      1379942214\n",
       "count             1\n",
       "Name: 1416, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_count_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb325f85-2a04-4346-af06-e01139e62393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_id      1164999973\n",
       "count        335500\n",
       "Name: 1839, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_count_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d76b7b63-bb59-46bc-a73e-3ce446aa7ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_ids=df._id.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb609910-d352-4634-9db1-0f80714d7e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f122113-0cd7-4a21-9df6-a968b51314bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eae71cbe-490b-4337-b08a-ddc46b5282b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'channel_id_1'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.create_index([(\"channel_id\", pymongo.ASCENDING)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95b8c214-cfa7-47c9-a939-4d793f4473c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def saveChannelDict(channel_id, messages):\n",
    "    savedir = 'channels/'\n",
    "    os.makedirs(savedir, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "    with open(savedir + str(channel_id) + '.jsonl', 'w+') as f:\n",
    "        for m in messages:\n",
    "            f.write(json.dumps(m) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5aa7ed4d-0aa2-4f12-ad24-491fd4504f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9042e56-4196-49ce-ae7d-9365b3622804",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                          | 0/5 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "5764it [00:00, 34726.11it/s]\u001b[A\n",
      " 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                        | 1/5 [00:00<00:01,  3.87it/s]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2613it [00:00, 20698.55it/s]\u001b[A\n",
      "5068it [00:00, 22740.78it/s]\u001b[A\n",
      "7789it [00:00, 24663.27it/s]\u001b[A\n",
      "10279it [00:00, 19681.92it/s]\u001b[A\n",
      "12927it [00:00, 21734.85it/s]\u001b[A\n",
      "15774it [00:00, 23765.04it/s]\u001b[A\n",
      "20962it [00:00, 23924.73it/s]\u001b[A\n",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                              | 2/5 [00:01<00:03,  1.03s/it]\n",
      "94it [00:00, 23818.32it/s]\n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                    | 3/5 [00:02<00:01,  1.15it/s]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "3496it [00:00, 34958.28it/s]\u001b[A\n",
      "7246it [00:00, 36450.44it/s]\u001b[A\n",
      "13340it [00:00, 37861.00it/s]\u001b[A\n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          | 4/5 [00:03<00:01,  1.00s/it]\n",
      "260it [00:00, 5396.98it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:04<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSV file exported successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#detect language of the messages\n",
    "import csv\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "# Initialize an empty list to store messages\n",
    "# Define the file path for the TSV file\n",
    "tsv_file = 'channel_languages.tsv'\n",
    "messages_text = []\n",
    "limited_channel_ids = channel_ids[:5]\n",
    "# Open the TSV file in write mode with newline='' to prevent extra newlines\n",
    "with open(tsv_file, 'w', newline='') as f:\n",
    "    # Create a CSV writer object\n",
    "    writer = csv.writer(f, delimiter='\\t')\n",
    "    \n",
    "    # Write the header row\n",
    "    writer.writerow(['channel_id', 'detected_language'])\n",
    "    \n",
    "    # Iterate over each channel ID\n",
    "    for channel_id in tqdm(limited_channel_ids):\n",
    "        # Iterate over each document in the collection for the current channel ID\n",
    "        for doc in tqdm(collection.find({'channel_id': channel_id})):\n",
    "            # Parse the 'data' field as JSON\n",
    "            data = json.loads(doc['data'])\n",
    "            # Extract the 'message' field from the 'data' field\n",
    "            message = data.get('message')\n",
    "            # If 'message' is not None, append it to the messages_text list\n",
    "            if message:\n",
    "                messages_text.append(message)\n",
    "        saveChannelDict(channel_id,messages_text)\n",
    "        # Concatenate all messages into a single string\n",
    "        all_messages_text = ' '.join(messages_text)\n",
    "        \n",
    "        # Detect the language of the concatenated text\n",
    "        detected_language = detect(all_messages_text)\n",
    "        \n",
    "        # Write the channel ID and detected language to the TSV file\n",
    "        writer.writerow([channel_id, detected_language])\n",
    "\n",
    "# Print confirmation message\n",
    "print(\"TSV file exported successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491a74e7-9015-42a0-b6e7-077a574904ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate MongoDB data dump\n",
    "import subprocess\n",
    "\n",
    "# Set your MongoDB connection parameters\n",
    "mongo_uri = \"mongodb://root:example@172.24.0.2:27017\"\n",
    "database_name = \"telegram\"\n",
    "collection_name = \"channel\"\n",
    "\n",
    "# Set the output directory for the dump\n",
    "output_directory = \"/home/telegram/telegram_pushshift/mongodump\"\n",
    "\n",
    "# Construct the mongodump command\n",
    "mongodump_cmd = f\"mongodump --uri={mongo_uri} --collection={collection_name} --db={database_name} --out={output_directory}  --authenticationDatabase=admin\"\n",
    "\n",
    "# Execute the command\n",
    "subprocess.run(mongodump_cmd, shell=True)\n",
    "\n",
    "print(\"MongoDB dump completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936cb2bf",
   "metadata": {},
   "source": [
    "## References \n",
    "\n",
    "1.https://pymongo.readthedocs.io/en/stable/\n",
    "\n",
    "2.https://www.mongodb.com/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09a5cb1",
   "metadata": {},
   "source": [
    "## Contact Details - Susmita.gangopadhyay@gesis.org"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
